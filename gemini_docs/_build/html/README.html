

<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Vertex AI SDK for Python &#8212; google-cloud-aiplatform  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  

  
  

  </head><body>

  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
          	<div class="admonition" id="python2-eol"> 
          	 As of January 1, 2020 this library no longer supports Python 2 on the latest released version. 
          	 Library versions released prior to that date will continue to be available. For more information please
          	 visit <a href="https://cloud.google.com/python/docs/python2-sunset/">Python 2 support on Google Cloud</a>.
          	</div>
            
  <section id="vertex-ai-sdk-for-python">
<h1>Vertex AI SDK for Python<a class="headerlink" href="#vertex-ai-sdk-for-python" title="Permalink to this heading">¶</a></h1>
<p><a class="reference external" href="https://github.com/googleapis/google-cloud-python/blob/main/README.rst#general-availability"><img alt="GA" src="https://img.shields.io/badge/support-ga-gold.svg" /></a> <a class="reference external" href="https://pypi.org/project/google-cloud-aiplatform/"><img alt="pypi" src="https://img.shields.io/pypi/v/google-cloud-aiplatform.svg" /></a> <a class="reference external" href="https://pypi.org/project/google-cloud-aiplatform/"><img alt="versions" src="https://img.shields.io/pypi/pyversions/google-cloud-aiplatform.svg" /></a></p>
<p><a class="reference external" href="https://cloud.google.com/vertex-ai/docs">Vertex AI</a>: Google Vertex AI is an integrated suite of machine learning tools and services for building and using ML models with AutoML or custom code. It offers both novices and experts the best workbench for the entire machine learning development lifecycle.</p>
<ul class="simple">
<li><p><a class="reference external" href="https://cloud.google.com/python/docs/reference/aiplatform/latest">Client Library Documentation</a></p></li>
<li><p><a class="reference external" href="https://cloud.google.com/vertex-ai/docs">Product Documentation</a></p></li>
</ul>
<section id="quick-start">
<h2>Quick Start<a class="headerlink" href="#quick-start" title="Permalink to this heading">¶</a></h2>
<p>In order to use this library, you first need to go through the following steps:</p>
<ol class="arabic simple">
<li><p><a class="reference external" href="https://console.cloud.google.com/project">Select or create a Cloud Platform project.</a></p></li>
<li><p><a class="reference external" href="https://cloud.google.com/billing/docs/how-to/modify-project#enable_billing_for_a_project">Enable billing for your project.</a></p></li>
<li><p><a class="reference external" href="https://cloud.google.com/vertex-ai/docs/start/use-vertex-ai-python-sdk">Enable the Vertex AI API.</a></p></li>
<li><p><a class="reference external" href="https://googleapis.dev/python/google-api-core/latest/auth.html">Setup Authentication.</a></p></li>
</ol>
<section id="installation">
<h3>Installation<a class="headerlink" href="#installation" title="Permalink to this heading">¶</a></h3>
<p>Install this library in a <a class="reference external" href="https://virtualenv.pypa.io/en/latest/">virtualenv</a> using pip. <a class="reference external" href="https://virtualenv.pypa.io/en/latest/">virtualenv</a> is a tool to
create isolated Python environments. The basic problem it addresses is one of
dependencies and versions, and indirectly permissions.</p>
<p>With <a class="reference external" href="https://virtualenv.pypa.io/en/latest/">virtualenv</a>, it’s possible to install this library without needing system
install permissions, and without clashing with the installed system
dependencies.</p>
<section id="mac-linux">
<h4>Mac/Linux<a class="headerlink" href="#mac-linux" title="Permalink to this heading">¶</a></h4>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">pip install virtualenv</span>
<span class="go">virtualenv &lt;your-env&gt;</span>
<span class="go">source &lt;your-env&gt;/bin/activate</span>
<span class="go">&lt;your-env&gt;/bin/pip install google-cloud-aiplatform</span>
</pre></div>
</div>
</section>
<section id="windows">
<h4>Windows<a class="headerlink" href="#windows" title="Permalink to this heading">¶</a></h4>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">pip install virtualenv</span>
<span class="go">virtualenv &lt;your-env&gt;</span>
<span class="go">&lt;your-env&gt;\Scripts\activate</span>
<span class="go">&lt;your-env&gt;\Scripts\pip.exe install google-cloud-aiplatform</span>
</pre></div>
</div>
</section>
<section id="supported-python-versions">
<h4>Supported Python Versions<a class="headerlink" href="#supported-python-versions" title="Permalink to this heading">¶</a></h4>
<p>Python &gt;= 3.8</p>
</section>
<section id="deprecated-python-versions">
<h4>Deprecated Python Versions<a class="headerlink" href="#deprecated-python-versions" title="Permalink to this heading">¶</a></h4>
<p>Python &lt;= 3.7.</p>
<p>The last version of this library compatible with Python 3.6 is google-cloud-aiplatform==1.12.1.</p>
</section>
</section>
<section id="overview">
<h3>Overview<a class="headerlink" href="#overview" title="Permalink to this heading">¶</a></h3>
<p>This section provides a brief overview of the Vertex AI SDK for Python. You can also reference the notebooks in <a class="reference external" href="https://github.com/GoogleCloudPlatform/vertex-ai-samples/tree/main/notebooks/community/sdk">vertex-ai-samples</a> for examples.</p>
<p>All publicly available SDK features can be found in the <code class="code docutils literal notranslate"><span class="pre">google/cloud/aiplatform</span></code> directory.
Under the hood, Vertex SDK builds on top of GAPIC, which stands for Google API CodeGen.
The GAPIC library code sits in <code class="code docutils literal notranslate"><span class="pre">google/cloud/aiplatform_v1</span></code> and <code class="code docutils literal notranslate"><span class="pre">google/cloud/aiplatform_v1beta1</span></code>,
and it is auto-generated from Google’s service proto files.</p>
<p>For most developers’ programmatic needs, they can follow these steps to figure out which libraries to import:</p>
<ol class="arabic simple">
<li><p>Look through <code class="code docutils literal notranslate"><span class="pre">google/cloud/aiplatform</span></code> first – Vertex SDK’s APIs will almost always be easier to use and more concise comparing with GAPIC</p></li>
<li><p>If the feature that you are looking for cannot be found there, look through <code class="code docutils literal notranslate"><span class="pre">aiplatform_v1</span></code> to see if it’s available in GAPIC</p></li>
<li><p>If it is still in beta phase, it will be available in <code class="code docutils literal notranslate"><span class="pre">aiplatform_v1beta1</span></code></p></li>
</ol>
<p>If none of the above scenarios could help you find the right tools for your task, please feel free to open a github issue and send us a feature request.</p>
<section id="importing">
<h4>Importing<a class="headerlink" href="#importing" title="Permalink to this heading">¶</a></h4>
<p>Vertex AI SDK resource based functionality can be used by importing the following namespace:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">google.cloud</span> <span class="kn">import</span> <span class="n">aiplatform</span>
</pre></div>
</div>
<p>Vertex AI SDK preview functionality can be used by importing the following namespace:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">vertexai</span> <span class="kn">import</span> <span class="n">preview</span>
</pre></div>
</div>
<p>Vertex AI SDK general availability (GA) functionality can be used by importing the following namespace:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">vertexai</span>
</pre></div>
</div>
</section>
<section id="initialization">
<h4>Initialization<a class="headerlink" href="#initialization" title="Permalink to this heading">¶</a></h4>
<p>Initialize the SDK to store common configurations that you use with the SDK.</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">aiplatform</span><span class="o">.</span><span class="n">init</span><span class="p">(</span>
    <span class="c1"># your Google Cloud Project ID or number</span>
    <span class="c1"># environment default used is not set</span>
    <span class="n">project</span><span class="o">=</span><span class="s1">&#39;my-project&#39;</span><span class="p">,</span>

    <span class="c1"># the Vertex AI region you will use</span>
    <span class="c1"># defaults to us-central1</span>
    <span class="n">location</span><span class="o">=</span><span class="s1">&#39;us-central1&#39;</span><span class="p">,</span>

    <span class="c1"># Google Cloud Storage bucket in same region as location</span>
    <span class="c1"># used to stage artifacts</span>
    <span class="n">staging_bucket</span><span class="o">=</span><span class="s1">&#39;gs://my_staging_bucket&#39;</span><span class="p">,</span>

    <span class="c1"># custom google.auth.credentials.Credentials</span>
    <span class="c1"># environment default credentials used if not set</span>
    <span class="n">credentials</span><span class="o">=</span><span class="n">my_credentials</span><span class="p">,</span>

    <span class="c1"># customer managed encryption key resource name</span>
    <span class="c1"># will be applied to all Vertex AI resources if set</span>
    <span class="n">encryption_spec_key_name</span><span class="o">=</span><span class="n">my_encryption_key_name</span><span class="p">,</span>

    <span class="c1"># the name of the experiment to use to track</span>
    <span class="c1"># logged metrics and parameters</span>
    <span class="n">experiment</span><span class="o">=</span><span class="s1">&#39;my-experiment&#39;</span><span class="p">,</span>

    <span class="c1"># description of the experiment above</span>
    <span class="n">experiment_description</span><span class="o">=</span><span class="s1">&#39;my experiment description&#39;</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="datasets">
<h4>Datasets<a class="headerlink" href="#datasets" title="Permalink to this heading">¶</a></h4>
<p>Vertex AI provides managed tabular, text, image, and video datasets. In the SDK, datasets can be used downstream to
train models.</p>
<p>To create a tabular dataset:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">my_dataset</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">TabularDataset</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">display_name</span><span class="o">=</span><span class="s2">&quot;my-dataset&quot;</span><span class="p">,</span> <span class="n">gcs_source</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;gs://path/to/my/dataset.csv&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>You can also create and import a dataset in separate steps:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">google.cloud</span> <span class="kn">import</span> <span class="n">aiplatform</span>

<span class="n">my_dataset</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">TextDataset</span><span class="o">.</span><span class="n">create</span><span class="p">(</span>
    <span class="n">display_name</span><span class="o">=</span><span class="s2">&quot;my-dataset&quot;</span><span class="p">)</span>

<span class="n">my_dataset</span><span class="o">.</span><span class="n">import</span><span class="p">(</span>
    <span class="n">gcs_source</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;gs://path/to/my/dataset.csv&#39;</span><span class="p">]</span>
    <span class="n">import_schema_uri</span><span class="o">=</span><span class="n">aiplatform</span><span class="o">.</span><span class="n">schema</span><span class="o">.</span><span class="n">dataset</span><span class="o">.</span><span class="n">ioformat</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">multi_label_classification</span>
<span class="p">)</span>
</pre></div>
</div>
<p>To get a previously created Dataset:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">ImageDataset</span><span class="p">(</span><span class="s1">&#39;projects/my-project/location/us-central1/datasets/</span><span class="si">{DATASET_ID}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Vertex AI supports a variety of dataset schemas. References to these schemas are available under the
<code class="code docutils literal notranslate"><span class="pre">aiplatform.schema.dataset</span></code> namespace. For more information on the supported dataset schemas please refer to the
<a class="reference external" href="https://cloud.google.com/ai-platform-unified/docs/datasets/prepare">Preparing data docs</a>.</p>
</section>
<section id="training">
<h4>Training<a class="headerlink" href="#training" title="Permalink to this heading">¶</a></h4>
<p>The Vertex AI SDK for Python allows you train Custom and AutoML Models.</p>
<p>You can train custom models using a custom Python script, custom Python package, or container.</p>
<p><strong>Preparing Your Custom Code</strong></p>
<p>Vertex AI custom training enables you to train on Vertex AI datasets and produce Vertex AI models. To do so your
script must adhere to the following contract:</p>
<p>It must read datasets from the environment variables populated by the training service:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;AIP_DATA_FORMAT&#39;</span><span class="p">]</span>  <span class="c1"># provides format of data</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;AIP_TRAINING_DATA_URI&#39;</span><span class="p">]</span>  <span class="c1"># uri to training split</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;AIP_VALIDATION_DATA_URI&#39;</span><span class="p">]</span>  <span class="c1"># uri to validation split</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;AIP_TEST_DATA_URI&#39;</span><span class="p">]</span>  <span class="c1"># uri to test split</span>
</pre></div>
</div>
<p>Please visit <a class="reference external" href="https://cloud.google.com/vertex-ai/docs/training/using-managed-datasets">Using a managed dataset in a custom training application</a> for a detailed overview.</p>
<p>It must write the model artifact to the environment variable populated by the training service:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;AIP_MODEL_DIR&#39;</span><span class="p">]</span>
</pre></div>
</div>
<p><strong>Running Training</strong></p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">job</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">CustomTrainingJob</span><span class="p">(</span>
    <span class="n">display_name</span><span class="o">=</span><span class="s2">&quot;my-training-job&quot;</span><span class="p">,</span>
    <span class="n">script_path</span><span class="o">=</span><span class="s2">&quot;training_script.py&quot;</span><span class="p">,</span>
    <span class="n">container_uri</span><span class="o">=</span><span class="s2">&quot;us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-2:latest&quot;</span><span class="p">,</span>
    <span class="n">requirements</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;gcsfs==0.7.1&quot;</span><span class="p">],</span>
    <span class="n">model_serving_container_image_uri</span><span class="o">=</span><span class="s2">&quot;us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-2:latest&quot;</span><span class="p">,</span>

<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">job</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">my_dataset</span><span class="p">,</span>
                <span class="n">replica_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">machine_type</span><span class="o">=</span><span class="s2">&quot;n1-standard-4&quot;</span><span class="p">,</span>
                <span class="n">accelerator_type</span><span class="o">=</span><span class="s1">&#39;NVIDIA_TESLA_K80&#39;</span><span class="p">,</span>
                <span class="n">accelerator_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>In the code block above <cite>my_dataset</cite> is managed dataset created in the <cite>Dataset</cite> section above. The <cite>model</cite> variable is a managed Vertex AI model that can be deployed or exported.</p>
</section>
</section>
</section>
<section id="automls">
<h2>AutoMLs<a class="headerlink" href="#automls" title="Permalink to this heading">¶</a></h2>
<p>The Vertex AI SDK for Python supports AutoML tabular, image, text, video, and forecasting.</p>
<p>To train an AutoML tabular model:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">TabularDataset</span><span class="p">(</span><span class="s1">&#39;projects/my-project/location/us-central1/datasets/</span><span class="si">{DATASET_ID}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">job</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">AutoMLTabularTrainingJob</span><span class="p">(</span>
  <span class="n">display_name</span><span class="o">=</span><span class="s2">&quot;train-automl&quot;</span><span class="p">,</span>
  <span class="n">optimization_prediction_type</span><span class="o">=</span><span class="s2">&quot;regression&quot;</span><span class="p">,</span>
  <span class="n">optimization_objective</span><span class="o">=</span><span class="s2">&quot;minimize-rmse&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">job</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
    <span class="n">dataset</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span>
    <span class="n">target_column</span><span class="o">=</span><span class="s2">&quot;target_column_name&quot;</span><span class="p">,</span>
    <span class="n">training_fraction_split</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span>
    <span class="n">validation_fraction_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">test_fraction_split</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span>
    <span class="n">budget_milli_node_hours</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">model_display_name</span><span class="o">=</span><span class="s2">&quot;my-automl-model&quot;</span><span class="p">,</span>
    <span class="n">disable_early_stopping</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="models">
<h2>Models<a class="headerlink" href="#models" title="Permalink to this heading">¶</a></h2>
<p>To get a model:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="s1">&#39;/projects/my-project/locations/us-central1/models/</span><span class="si">{MODEL_ID}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>To upload a model:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">Model</span><span class="o">.</span><span class="n">upload</span><span class="p">(</span>
    <span class="n">display_name</span><span class="o">=</span><span class="s1">&#39;my-model&#39;</span><span class="p">,</span>
    <span class="n">artifact_uri</span><span class="o">=</span><span class="s2">&quot;gs://python/to/my/model/dir&quot;</span><span class="p">,</span>
    <span class="n">serving_container_image_uri</span><span class="o">=</span><span class="s2">&quot;us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-2:latest&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
<p>To deploy a model:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">endpoint</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">deploy</span><span class="p">(</span><span class="n">machine_type</span><span class="o">=</span><span class="s2">&quot;n1-standard-4&quot;</span><span class="p">,</span>
                        <span class="n">min_replica_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                        <span class="n">max_replica_count</span><span class="o">=</span><span class="mi">5</span>
                        <span class="n">machine_type</span><span class="o">=</span><span class="s1">&#39;n1-standard-4&#39;</span><span class="p">,</span>
                        <span class="n">accelerator_type</span><span class="o">=</span><span class="s1">&#39;NVIDIA_TESLA_K80&#39;</span><span class="p">,</span>
                        <span class="n">accelerator_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Please visit <a class="reference external" href="https://cloud.google.com/vertex-ai/docs/general/import-model">Importing models to Vertex AI</a> for a detailed overview:</p>
</section>
<section id="model-evaluation">
<h2>Model Evaluation<a class="headerlink" href="#model-evaluation" title="Permalink to this heading">¶</a></h2>
<p>The Vertex AI SDK for Python currently supports getting model evaluation metrics for all AutoML models.</p>
<p>To list all model evaluations for a model:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="s1">&#39;projects/my-project/locations/us-central1/models/</span><span class="si">{MODEL_ID}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">evaluations</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">list_model_evaluations</span><span class="p">()</span>
</pre></div>
</div>
<p>To get the model evaluation resource for a given model:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="s1">&#39;projects/my-project/locations/us-central1/models/</span><span class="si">{MODEL_ID}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># returns the first evaluation with no arguments, you can also pass the evaluation ID</span>
<span class="n">evaluation</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">get_model_evaluation</span><span class="p">()</span>

<span class="n">eval_metrics</span> <span class="o">=</span> <span class="n">evaluation</span><span class="o">.</span><span class="n">metrics</span>
</pre></div>
</div>
<p>You can also create a reference to your model evaluation directly by passing in the resource name of the model evaluation:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">evaluation</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">ModelEvaluation</span><span class="p">(</span>
  <span class="n">evaluation_name</span><span class="o">=</span><span class="s1">&#39;projects/my-project/locations/us-central1/models/</span><span class="si">{MODEL_ID}</span><span class="s1">/evaluations/</span><span class="si">{EVALUATION_ID}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Alternatively, you can create a reference to your evaluation by passing in the model and evaluation IDs:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">evaluation</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">ModelEvaluation</span><span class="p">(</span>
  <span class="n">evaluation_name</span><span class="o">=</span><span class="p">{</span><span class="n">EVALUATION_ID</span><span class="p">},</span>
  <span class="n">model_id</span><span class="o">=</span><span class="p">{</span><span class="n">MODEL_ID</span><span class="p">})</span>
</pre></div>
</div>
</section>
<section id="batch-prediction">
<h2>Batch Prediction<a class="headerlink" href="#batch-prediction" title="Permalink to this heading">¶</a></h2>
<p>To create a batch prediction job:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="s1">&#39;/projects/my-project/locations/us-central1/models/</span><span class="si">{MODEL_ID}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">batch_prediction_job</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">batch_predict</span><span class="p">(</span>
  <span class="n">job_display_name</span><span class="o">=</span><span class="s1">&#39;my-batch-prediction-job&#39;</span><span class="p">,</span>
  <span class="n">instances_format</span><span class="o">=</span><span class="s1">&#39;csv&#39;</span><span class="p">,</span>
  <span class="n">machine_type</span><span class="o">=</span><span class="s1">&#39;n1-standard-4&#39;</span><span class="p">,</span>
  <span class="n">gcs_source</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;gs://path/to/my/file.csv&#39;</span><span class="p">],</span>
  <span class="n">gcs_destination_prefix</span><span class="o">=</span><span class="s1">&#39;gs://path/to/my/batch_prediction/results/&#39;</span><span class="p">,</span>
  <span class="n">service_account</span><span class="o">=</span><span class="s1">&#39;my-sa@my-project.iam.gserviceaccount.com&#39;</span>
<span class="p">)</span>
</pre></div>
</div>
<p>You can also create a batch prediction job asynchronously by including the <cite>sync=False</cite> argument:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">batch_prediction_job</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">batch_predict</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">sync</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># wait for resource to be created</span>
<span class="n">batch_prediction_job</span><span class="o">.</span><span class="n">wait_for_resource_creation</span><span class="p">()</span>

<span class="c1"># get the state</span>
<span class="n">batch_prediction_job</span><span class="o">.</span><span class="n">state</span>

<span class="c1"># block until job is complete</span>
<span class="n">batch_prediction_job</span><span class="o">.</span><span class="n">wait</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="endpoints">
<h2>Endpoints<a class="headerlink" href="#endpoints" title="Permalink to this heading">¶</a></h2>
<p>To create an endpoint:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">endpoint</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">Endpoint</span><span class="o">.</span><span class="n">create</span><span class="p">(</span><span class="n">display_name</span><span class="o">=</span><span class="s1">&#39;my-endpoint&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>To deploy a model to a created endpoint:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="s1">&#39;/projects/my-project/locations/us-central1/models/</span><span class="si">{MODEL_ID}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">endpoint</span><span class="o">.</span><span class="n">deploy</span><span class="p">(</span><span class="n">model</span><span class="p">,</span>
                <span class="n">min_replica_count</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">max_replica_count</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                <span class="n">machine_type</span><span class="o">=</span><span class="s1">&#39;n1-standard-4&#39;</span><span class="p">,</span>
                <span class="n">accelerator_type</span><span class="o">=</span><span class="s1">&#39;NVIDIA_TESLA_K80&#39;</span><span class="p">,</span>
                <span class="n">accelerator_count</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>To get predictions from endpoints:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">endpoint</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">instances</span><span class="o">=</span><span class="p">[[</span><span class="mf">6.7</span><span class="p">,</span> <span class="mf">3.1</span><span class="p">,</span> <span class="mf">4.7</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">],</span> <span class="p">[</span><span class="mf">4.6</span><span class="p">,</span> <span class="mf">3.1</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]])</span>
</pre></div>
</div>
<p>To undeploy models from an endpoint:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">endpoint</span><span class="o">.</span><span class="n">undeploy_all</span><span class="p">()</span>
</pre></div>
</div>
<p>To delete an endpoint:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">endpoint</span><span class="o">.</span><span class="n">delete</span><span class="p">()</span>
</pre></div>
</div>
</section>
<section id="pipelines">
<h2>Pipelines<a class="headerlink" href="#pipelines" title="Permalink to this heading">¶</a></h2>
<p>To create a Vertex AI Pipeline run and monitor until completion:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Instantiate PipelineJob object</span>
<span class="n">pl</span> <span class="o">=</span> <span class="n">PipelineJob</span><span class="p">(</span>
    <span class="n">display_name</span><span class="o">=</span><span class="s2">&quot;My first pipeline&quot;</span><span class="p">,</span>

    <span class="c1"># Whether or not to enable caching</span>
    <span class="c1"># True = always cache pipeline step result</span>
    <span class="c1"># False = never cache pipeline step result</span>
    <span class="c1"># None = defer to cache option for each pipeline component in the pipeline definition</span>
    <span class="n">enable_caching</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>

    <span class="c1"># Local or GCS path to a compiled pipeline definition</span>
    <span class="n">template_path</span><span class="o">=</span><span class="s2">&quot;pipeline.json&quot;</span><span class="p">,</span>

    <span class="c1"># Dictionary containing input parameters for your pipeline</span>
    <span class="n">parameter_values</span><span class="o">=</span><span class="n">parameter_values</span><span class="p">,</span>

    <span class="c1"># GCS path to act as the pipeline root</span>
    <span class="n">pipeline_root</span><span class="o">=</span><span class="n">pipeline_root</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Execute pipeline in Vertex AI and monitor until completion</span>
<span class="n">pl</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
  <span class="c1"># Email address of service account to use for the pipeline run</span>
  <span class="c1"># You must have iam.serviceAccounts.actAs permission on the service account to use it</span>
  <span class="n">service_account</span><span class="o">=</span><span class="n">service_account</span><span class="p">,</span>

  <span class="c1"># Whether this function call should be synchronous (wait for pipeline run to finish before terminating)</span>
  <span class="c1"># or asynchronous (return immediately)</span>
  <span class="n">sync</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
<p>To create a Vertex AI Pipeline without monitoring until completion, use <cite>submit</cite> instead of <cite>run</cite>:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Instantiate PipelineJob object</span>
<span class="n">pl</span> <span class="o">=</span> <span class="n">PipelineJob</span><span class="p">(</span>
    <span class="n">display_name</span><span class="o">=</span><span class="s2">&quot;My first pipeline&quot;</span><span class="p">,</span>

    <span class="c1"># Whether or not to enable caching</span>
    <span class="c1"># True = always cache pipeline step result</span>
    <span class="c1"># False = never cache pipeline step result</span>
    <span class="c1"># None = defer to cache option for each pipeline component in the pipeline definition</span>
    <span class="n">enable_caching</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>

    <span class="c1"># Local or GCS path to a compiled pipeline definition</span>
    <span class="n">template_path</span><span class="o">=</span><span class="s2">&quot;pipeline.json&quot;</span><span class="p">,</span>

    <span class="c1"># Dictionary containing input parameters for your pipeline</span>
    <span class="n">parameter_values</span><span class="o">=</span><span class="n">parameter_values</span><span class="p">,</span>

    <span class="c1"># GCS path to act as the pipeline root</span>
    <span class="n">pipeline_root</span><span class="o">=</span><span class="n">pipeline_root</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Submit the Pipeline to Vertex AI</span>
<span class="n">pl</span><span class="o">.</span><span class="n">submit</span><span class="p">(</span>
  <span class="c1"># Email address of service account to use for the pipeline run</span>
  <span class="c1"># You must have iam.serviceAccounts.actAs permission on the service account to use it</span>
  <span class="n">service_account</span><span class="o">=</span><span class="n">service_account</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="explainable-ai-get-metadata">
<h2>Explainable AI: Get Metadata<a class="headerlink" href="#explainable-ai-get-metadata" title="Permalink to this heading">¶</a></h2>
<p>To get metadata in dictionary format from TensorFlow 1 models:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">google.cloud.aiplatform.explain.metadata.tf.v1</span> <span class="kn">import</span> <span class="n">saved_model_metadata_builder</span>

<span class="n">builder</span> <span class="o">=</span> <span class="n">saved_model_metadata_builder</span><span class="o">.</span><span class="n">SavedModelMetadataBuilder</span><span class="p">(</span>
          <span class="s1">&#39;gs://python/to/my/model/dir&#39;</span><span class="p">,</span> <span class="n">tags</span><span class="o">=</span><span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">tag_constants</span><span class="o">.</span><span class="n">SERVING</span><span class="p">]</span>
      <span class="p">)</span>
<span class="n">generated_md</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">get_metadata</span><span class="p">()</span>
</pre></div>
</div>
<p>To get metadata in dictionary format from TensorFlow 2 models:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">google.cloud.aiplatform.explain.metadata.tf.v2</span> <span class="kn">import</span> <span class="n">saved_model_metadata_builder</span>

<span class="n">builder</span> <span class="o">=</span> <span class="n">saved_model_metadata_builder</span><span class="o">.</span><span class="n">SavedModelMetadataBuilder</span><span class="p">(</span><span class="s1">&#39;gs://python/to/my/model/dir&#39;</span><span class="p">)</span>
<span class="n">generated_md</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">get_metadata</span><span class="p">()</span>
</pre></div>
</div>
<p>To use Explanation Metadata in endpoint deployment and model upload:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">explanation_metadata</span> <span class="o">=</span> <span class="n">builder</span><span class="o">.</span><span class="n">get_metadata_protobuf</span><span class="p">()</span>

<span class="c1"># To deploy a model to an endpoint with explanation</span>
<span class="n">model</span><span class="o">.</span><span class="n">deploy</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">explanation_metadata</span><span class="o">=</span><span class="n">explanation_metadata</span><span class="p">)</span>

<span class="c1"># To deploy a model to a created endpoint with explanation</span>
<span class="n">endpoint</span><span class="o">.</span><span class="n">deploy</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">explanation_metadata</span><span class="o">=</span><span class="n">explanation_metadata</span><span class="p">)</span>

<span class="c1"># To upload a model with explanation</span>
<span class="n">aiplatform</span><span class="o">.</span><span class="n">Model</span><span class="o">.</span><span class="n">upload</span><span class="p">(</span><span class="o">...</span><span class="p">,</span> <span class="n">explanation_metadata</span><span class="o">=</span><span class="n">explanation_metadata</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="cloud-profiler">
<h2>Cloud Profiler<a class="headerlink" href="#cloud-profiler" title="Permalink to this heading">¶</a></h2>
<p>Cloud Profiler allows you to profile your remote Vertex AI Training jobs on demand and visualize the results in Vertex AI Tensorboard.</p>
<p>To start using the profiler with TensorFlow, update your training script to include the following:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">google.cloud.aiplatform.training_utils</span> <span class="kn">import</span> <span class="n">cloud_profiler</span>
<span class="o">...</span>
<span class="n">cloud_profiler</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
</pre></div>
</div>
<p>Next, run the job with with a Vertex AI TensorBoard instance. For full details on how to do this, visit <a class="reference external" href="https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-overview">https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-overview</a></p>
<p>Finally, visit your TensorBoard in your Google Cloud Console, navigate to the “Profile” tab, and click the <cite>Capture Profile</cite> button. This will allow users to capture profiling statistics for the running jobs.</p>
<section id="next-steps">
<h3>Next Steps<a class="headerlink" href="#next-steps" title="Permalink to this heading">¶</a></h3>
<ul class="simple">
<li><p>Read the <a class="reference external" href="https://cloud.google.com/python/docs/reference/aiplatform/latest">Client Library Documentation</a> for Vertex AI
API to see other available methods on the client.</p></li>
<li><p>Read the <a class="reference external" href="https://cloud.google.com/vertex-ai/docs">Vertex AI API Product documentation</a> to learn
more about the product and see How-to Guides.</p></li>
<li><p>View this <a class="reference external" href="https://github.com/googleapis/google-cloud-python/blob/main/README.rst">README</a> to see the full list of Cloud
APIs that we cover.</p></li>
</ul>
</section>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">google-cloud-aiplatform</a></h1>



<p class="blurb">Google Cloud Client Libraries for google-cloud-aiplatform</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=googleapis&repo=python-aiplatform&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="vertexai/services.html">Vertex AI SDK</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2019, Google.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 5.0.2</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
      |
      <a href="_sources/README.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    
    <a href="https://github.com/googleapis/python-aiplatform" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://github.blog/wp-content/uploads/2008/12/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>