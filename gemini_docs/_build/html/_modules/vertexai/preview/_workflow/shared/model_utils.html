

<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>vertexai.preview._workflow.shared.model_utils &#8212; google-cloud-aiplatform  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../../../_static/alabaster.css" />
    <script data-url_root="../../../../../" id="documentation_options" src="../../../../../_static/documentation_options.js"></script>
    <script src="../../../../../_static/jquery.js"></script>
    <script src="../../../../../_static/underscore.js"></script>
    <script src="../../../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../../../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>

  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
          	<div class="admonition" id="python2-eol"> 
          	 As of January 1, 2020 this library no longer supports Python 2 on the latest released version. 
          	 Library versions released prior to that date will continue to be available. For more information please
          	 visit <a href="https://cloud.google.com/python/docs/python2-sunset/">Python 2 support on Google Cloud</a>.
          	</div>
            
  <h1>Source code for vertexai.preview._workflow.shared.model_utils</h1><div class="highlight"><pre>
<span></span><span class="c1"># -*- coding: utf-8 -*-</span>

<span class="c1"># Copyright 2023 Google LLC</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     http://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="c1">#</span>

<span class="sd">&quot;&quot;&quot;Model utils.</span>

<span class="sd">Push trained model from local to Model Registry, and pull Model Registry model</span>
<span class="sd">to local for uptraining.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">from</span> <span class="nn">google.cloud</span> <span class="kn">import</span> <span class="n">aiplatform</span>
<span class="kn">from</span> <span class="nn">google.cloud.aiplatform</span> <span class="kn">import</span> <span class="n">base</span>
<span class="kn">from</span> <span class="nn">google.cloud.aiplatform</span> <span class="kn">import</span> <span class="n">utils</span>
<span class="kn">from</span> <span class="nn">google.cloud.aiplatform</span> <span class="kn">import</span> <span class="n">jobs</span> <span class="k">as</span> <span class="n">aiplatform_jobs</span>
<span class="kn">import</span> <span class="nn">vertexai</span>
<span class="kn">from</span> <span class="nn">vertexai.preview._workflow</span> <span class="kn">import</span> <span class="n">driver</span>
<span class="kn">from</span> <span class="nn">vertexai.preview._workflow.serialization_engine</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">any_serializer</span><span class="p">,</span>
    <span class="n">serializers_base</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># These need to be imported to be included in _ModelGardenModel.__init_subclass__</span>
<span class="kn">from</span> <span class="nn">vertexai.language_models</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_language_models</span><span class="p">,</span>
<span class="p">)</span>  <span class="c1"># pylint:disable=unused-import</span>
<span class="kn">from</span> <span class="nn">vertexai.vision_models</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_vision_models</span><span class="p">,</span>
<span class="p">)</span>  <span class="c1"># pylint:disable=unused-import</span>
<span class="kn">from</span> <span class="nn">vertexai._model_garden</span> <span class="kn">import</span> <span class="n">_model_garden_models</span>
<span class="kn">from</span> <span class="nn">google.cloud.aiplatform</span> <span class="kn">import</span> <span class="n">_publisher_models</span>
<span class="kn">from</span> <span class="nn">vertexai.preview._workflow.executor</span> <span class="kn">import</span> <span class="n">training</span>
<span class="kn">from</span> <span class="nn">google.cloud.aiplatform.compat.types</span> <span class="kn">import</span> <span class="n">job_state</span> <span class="k">as</span> <span class="n">gca_job_state</span>


<span class="n">_SKLEARN_FILE_NAME</span> <span class="o">=</span> <span class="s2">&quot;model.pkl&quot;</span>
<span class="n">_TF_DIR_NAME</span> <span class="o">=</span> <span class="s2">&quot;saved_model&quot;</span>
<span class="n">_PYTORCH_FILE_NAME</span> <span class="o">=</span> <span class="s2">&quot;model.mar&quot;</span>
<span class="n">_REWRAPPER_NAME</span> <span class="o">=</span> <span class="s2">&quot;rewrapper&quot;</span>

<span class="n">_CUSTOM_JOB_DIR</span> <span class="o">=</span> <span class="s2">&quot;custom_job&quot;</span>
<span class="n">_INPUT_DIR</span> <span class="o">=</span> <span class="s2">&quot;input&quot;</span>
<span class="n">_OUTPUT_DIR</span> <span class="o">=</span> <span class="s2">&quot;output&quot;</span>
<span class="n">_OUTPUT_ESTIMATOR_DIR</span> <span class="o">=</span> <span class="s2">&quot;output_estimator&quot;</span>
<span class="n">_OUTPUT_PREDICTIONS_DIR</span> <span class="o">=</span> <span class="s2">&quot;output_predictions&quot;</span>


<span class="n">_LOGGER</span> <span class="o">=</span> <span class="n">base</span><span class="o">.</span><span class="n">Logger</span><span class="p">(</span><span class="s2">&quot;vertexai.remote_execution&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_get_model_file_from_image_uri</span><span class="p">(</span><span class="n">container_image_uri</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Gets the model file from the container image URI.</span>

<span class="sd">    Args:</span>
<span class="sd">        container_image_uri (str):</span>
<span class="sd">          The image URI of the container from the training job.</span>

<span class="sd">    Returns:</span>
<span class="sd">        str:</span>
<span class="sd">          The model file name.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># sklearn, TF, PyTorch model extensions for retraining.</span>
    <span class="c1"># PyTorch serv will need model.mar</span>
    <span class="k">if</span> <span class="s2">&quot;tf&quot;</span> <span class="ow">in</span> <span class="n">container_image_uri</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;&quot;</span>
    <span class="k">elif</span> <span class="s2">&quot;sklearn&quot;</span> <span class="ow">in</span> <span class="n">container_image_uri</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">_SKLEARN_FILE_NAME</span>
    <span class="k">elif</span> <span class="s2">&quot;pytorch&quot;</span> <span class="ow">in</span> <span class="n">container_image_uri</span><span class="p">:</span>
        <span class="c1"># Assume the pretrained model will be pulled for uptraining.</span>
        <span class="k">return</span> <span class="n">_PYTORCH_FILE_NAME</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Support loading PyTorch, scikit-learn and TensorFlow only.&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_verify_custom_job</span><span class="p">(</span><span class="n">job</span><span class="p">:</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">CustomJob</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Verifies the provided CustomJob was created with SDK 2.0.</span>

<span class="sd">    Args:</span>
<span class="sd">        job (aiplatform.CustomJob):</span>
<span class="sd">          The CustomJob resource</span>

<span class="sd">    Raises:</span>
<span class="sd">        If the provided job wasn&#39;t created with SDK 2.0.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="p">(</span>
        <span class="ow">not</span> <span class="n">job</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;trained_by_vertex_ai&quot;</span><span class="p">)</span>
        <span class="ow">or</span> <span class="n">job</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;trained_by_vertex_ai&quot;</span><span class="p">)</span> <span class="o">!=</span> <span class="s2">&quot;true&quot;</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;This job wasn&#39;t created with SDK remote training, or it was created with a Vertex SDK version &lt;= 1.32.0&quot;</span>
        <span class="p">)</span>


<span class="k">def</span> <span class="nf">_generate_remote_job_output_path</span><span class="p">(</span><span class="n">base_gcs_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generates the GCS output path of the remote training job.</span>

<span class="sd">    Args:</span>
<span class="sd">        base_gcs_dir (str):</span>
<span class="sd">          The base GCS directory for the remote training job.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">base_gcs_dir</span><span class="p">,</span> <span class="n">_OUTPUT_DIR</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_get_model_from_successful_custom_job</span><span class="p">(</span>
    <span class="n">job_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;sklearn.base.BaseEstimator&quot;</span><span class="p">,</span> <span class="s2">&quot;tf.Module&quot;</span><span class="p">,</span> <span class="s2">&quot;torch.nn.Module&quot;</span><span class="p">]:</span>

    <span class="n">serializer</span> <span class="o">=</span> <span class="n">any_serializer</span><span class="o">.</span><span class="n">AnySerializer</span><span class="p">()</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">serializer</span><span class="o">.</span><span class="n">deserialize</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">_generate_remote_job_output_path</span><span class="p">(</span><span class="n">job_dir</span><span class="p">),</span> <span class="n">_OUTPUT_ESTIMATOR_DIR</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">rewrapper</span> <span class="o">=</span> <span class="n">serializer</span><span class="o">.</span><span class="n">deserialize</span><span class="p">(</span>
        <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">_generate_remote_job_output_path</span><span class="p">(</span><span class="n">job_dir</span><span class="p">),</span> <span class="n">_REWRAPPER_NAME</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">rewrapper</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>


<span class="k">def</span> <span class="nf">_register_sklearn_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="s2">&quot;sklearn.base.BaseEstimator&quot;</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">serializer</span><span class="p">:</span> <span class="n">serializers_base</span><span class="o">.</span><span class="n">Serializer</span><span class="p">,</span>
    <span class="n">staging_bucket</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">rewrapper</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">Model</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Register sklearn model.&quot;&quot;&quot;</span>
    <span class="n">unique_model_name</span> <span class="o">=</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;vertex-ai-registered-sklearn-model-</span><span class="si">{</span><span class="n">utils</span><span class="o">.</span><span class="n">timestamped_unique_name</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="n">gcs_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">staging_bucket</span><span class="p">,</span> <span class="n">unique_model_name</span><span class="p">)</span>
    <span class="c1"># serialize rewrapper</span>
    <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">gcs_dir</span><span class="p">,</span> <span class="n">_REWRAPPER_NAME</span><span class="p">)</span>
    <span class="n">serializer</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="n">rewrapper</span><span class="p">,</span> <span class="n">file_path</span><span class="p">)</span>
    <span class="c1"># serialize model</span>
    <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">gcs_dir</span><span class="p">,</span> <span class="n">_SKLEARN_FILE_NAME</span><span class="p">)</span>
    <span class="n">serializer</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">file_path</span><span class="p">)</span>

    <span class="n">container_image_uri</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">helpers</span><span class="o">.</span><span class="n">get_prebuilt_prediction_container_uri</span><span class="p">(</span>
        <span class="n">framework</span><span class="o">=</span><span class="s2">&quot;sklearn&quot;</span><span class="p">,</span>
        <span class="n">framework_version</span><span class="o">=</span><span class="s2">&quot;1.0&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">vertex_model</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">Model</span><span class="o">.</span><span class="n">upload</span><span class="p">(</span>
        <span class="n">display_name</span><span class="o">=</span><span class="n">unique_model_name</span><span class="p">,</span>
        <span class="n">artifact_uri</span><span class="o">=</span><span class="n">gcs_dir</span><span class="p">,</span>
        <span class="n">serving_container_image_uri</span><span class="o">=</span><span class="n">container_image_uri</span><span class="p">,</span>
        <span class="n">labels</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;registered_by_vertex_ai&quot;</span><span class="p">:</span> <span class="s2">&quot;true&quot;</span><span class="p">},</span>
        <span class="n">sync</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">vertex_model</span>


<span class="k">def</span> <span class="nf">_register_tf_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="s2">&quot;tensorflow.Module&quot;</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">serializer</span><span class="p">:</span> <span class="n">serializers_base</span><span class="o">.</span><span class="n">Serializer</span><span class="p">,</span>
    <span class="n">staging_bucket</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">rewrapper</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">use_gpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">Model</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Register TensorFlow model.&quot;&quot;&quot;</span>
    <span class="n">unique_model_name</span> <span class="o">=</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;vertex-ai-registered-tensorflow-model-</span><span class="si">{</span><span class="n">utils</span><span class="o">.</span><span class="n">timestamped_unique_name</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="n">gcs_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">staging_bucket</span><span class="p">,</span> <span class="n">unique_model_name</span><span class="p">)</span>
    <span class="c1"># serialize rewrapper</span>
    <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">gcs_dir</span><span class="p">,</span> <span class="n">_TF_DIR_NAME</span> <span class="o">+</span> <span class="s2">&quot;/&quot;</span> <span class="o">+</span> <span class="n">_REWRAPPER_NAME</span><span class="p">)</span>
    <span class="n">serializer</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="n">rewrapper</span><span class="p">,</span> <span class="n">file_path</span><span class="p">)</span>
    <span class="c1"># serialize model</span>
    <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">gcs_dir</span><span class="p">,</span> <span class="n">_TF_DIR_NAME</span><span class="p">)</span>
    <span class="c1"># The default serialization format for keras models is &quot;keras&quot;, but this</span>
    <span class="c1"># format is not yet supported by the model upload (eventually prediction</span>
    <span class="c1"># services). See the code here:</span>
    <span class="c1"># https://source.corp.google.com/piper///depot/google3/third_party/py/google/cloud/aiplatform/aiplatform/models.py;rcl=561677645;l=3141</span>
    <span class="n">serializer</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">file_path</span><span class="p">,</span> <span class="n">save_format</span><span class="o">=</span><span class="s2">&quot;tf&quot;</span><span class="p">)</span>

    <span class="n">container_image_uri</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">helpers</span><span class="o">.</span><span class="n">get_prebuilt_prediction_container_uri</span><span class="p">(</span>
        <span class="n">framework</span><span class="o">=</span><span class="s2">&quot;tensorflow&quot;</span><span class="p">,</span>
        <span class="n">framework_version</span><span class="o">=</span><span class="s2">&quot;2.11&quot;</span><span class="p">,</span>
        <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;gpu&quot;</span> <span class="k">if</span> <span class="n">use_gpu</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">vertex_model</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">Model</span><span class="o">.</span><span class="n">upload</span><span class="p">(</span>
        <span class="n">display_name</span><span class="o">=</span><span class="n">unique_model_name</span><span class="p">,</span>
        <span class="n">artifact_uri</span><span class="o">=</span><span class="n">file_path</span><span class="p">,</span>
        <span class="n">serving_container_image_uri</span><span class="o">=</span><span class="n">container_image_uri</span><span class="p">,</span>
        <span class="n">labels</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;registered_by_vertex_ai&quot;</span><span class="p">:</span> <span class="s2">&quot;true&quot;</span><span class="p">},</span>
        <span class="n">sync</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">vertex_model</span>


<span class="k">def</span> <span class="nf">_register_pytorch_model</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="s2">&quot;torch.nn.Module&quot;</span><span class="p">,</span>  <span class="c1"># noqa: F821</span>
    <span class="n">serializer</span><span class="p">:</span> <span class="n">serializers_base</span><span class="o">.</span><span class="n">Serializer</span><span class="p">,</span>
    <span class="n">staging_bucket</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">rewrapper</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">use_gpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">Model</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Register PyTorch model.&quot;&quot;&quot;</span>
    <span class="n">unique_model_name</span> <span class="o">=</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;vertex-ai-registered-pytorch-model-</span><span class="si">{</span><span class="n">utils</span><span class="o">.</span><span class="n">timestamped_unique_name</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span>
    <span class="p">)</span>
    <span class="n">gcs_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">staging_bucket</span><span class="p">,</span> <span class="n">unique_model_name</span><span class="p">)</span>

    <span class="c1"># serialize rewrapper</span>
    <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">gcs_dir</span><span class="p">,</span> <span class="n">_REWRAPPER_NAME</span><span class="p">)</span>
    <span class="n">serializer</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="n">rewrapper</span><span class="p">,</span> <span class="n">file_path</span><span class="p">)</span>

    <span class="c1"># This archive model is required for using prediction pre-built container</span>
    <span class="n">archive_file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">gcs_dir</span><span class="p">,</span> <span class="n">_PYTORCH_FILE_NAME</span><span class="p">)</span>
    <span class="n">serializer</span><span class="o">.</span><span class="n">serialize</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">archive_file_path</span><span class="p">)</span>

    <span class="n">container_image_uri</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">helpers</span><span class="o">.</span><span class="n">get_prebuilt_prediction_container_uri</span><span class="p">(</span>
        <span class="n">framework</span><span class="o">=</span><span class="s2">&quot;pytorch&quot;</span><span class="p">,</span>
        <span class="n">framework_version</span><span class="o">=</span><span class="s2">&quot;1.12&quot;</span><span class="p">,</span>
        <span class="n">accelerator</span><span class="o">=</span><span class="s2">&quot;gpu&quot;</span> <span class="k">if</span> <span class="n">use_gpu</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">vertex_model</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">Model</span><span class="o">.</span><span class="n">upload</span><span class="p">(</span>
        <span class="n">display_name</span><span class="o">=</span><span class="n">unique_model_name</span><span class="p">,</span>
        <span class="n">artifact_uri</span><span class="o">=</span><span class="n">gcs_dir</span><span class="p">,</span>
        <span class="n">serving_container_image_uri</span><span class="o">=</span><span class="n">container_image_uri</span><span class="p">,</span>
        <span class="n">labels</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;registered_by_vertex_ai&quot;</span><span class="p">:</span> <span class="s2">&quot;true&quot;</span><span class="p">},</span>
        <span class="n">sync</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">vertex_model</span>


<span class="k">def</span> <span class="nf">_get_publisher_model_resource</span><span class="p">(</span>
    <span class="n">short_model_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">_publisher_models</span><span class="o">.</span><span class="n">_PublisherModel</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Gets the PublisherModel resource from the short model name.</span>

<span class="sd">    Args:</span>
<span class="sd">        short_model_name (str):</span>
<span class="sd">            Required. The short name for the model, for example &#39;text-bison@001&#39;</span>

<span class="sd">    Returns:</span>
<span class="sd">        A _PublisherModel instance pointing to the PublisherModel resource for</span>
<span class="sd">        this model.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError:</span>
<span class="sd">            If no PublisherModel resource was found for the given short_model_name.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="s2">&quot;/&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">short_model_name</span><span class="p">:</span>
        <span class="n">short_model_name</span> <span class="o">=</span> <span class="s2">&quot;publishers/google/models/&quot;</span> <span class="o">+</span> <span class="n">short_model_name</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">publisher_model_resource</span> <span class="o">=</span> <span class="n">_publisher_models</span><span class="o">.</span><span class="n">_PublisherModel</span><span class="p">(</span>
            <span class="n">resource_name</span><span class="o">=</span><span class="n">short_model_name</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">publisher_model_resource</span>
    <span class="k">except</span><span class="p">:</span>  <span class="c1"># noqa: E722</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Please provide a valid Model Garden model resource.&quot;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_check_from_pretrained_passed_exactly_one_arg</span><span class="p">(</span><span class="n">fn_args</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Checks exactly one argument was passed to from_pretrained.</span>

<span class="sd">    This supports an expanding number of arguments added to from_pretrained.</span>

<span class="sd">    Args:</span>
<span class="sd">        fn_args (Dict[str, Any]):</span>
<span class="sd">            Required. A dictionary of the arguments passed to from_pretrained.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError:</span>
<span class="sd">            If more than one arg or no args were passed to from_pretrained.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">passed_args</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">argval</span> <span class="ow">in</span> <span class="n">fn_args</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">argval</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">passed_args</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">passed_args</span> <span class="o">!=</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Exactly one of </span><span class="si">{</span><span class="nb">list</span><span class="p">(</span><span class="n">fn_args</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2"> must be provided to from_pretrained.&quot;</span>
        <span class="p">)</span>


<div class="viewcode-block" id="register"><a class="viewcode-back" href="../../../../../vertexai/services.html#vertexai.preview.register">[docs]</a><span class="k">def</span> <span class="nf">register</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
        <span class="s2">&quot;sklearn.base.BaseEstimator&quot;</span><span class="p">,</span> <span class="s2">&quot;tf.Module&quot;</span><span class="p">,</span> <span class="s2">&quot;torch.nn.Module&quot;</span>  <span class="c1"># noqa: F821</span>
    <span class="p">],</span>
    <span class="n">use_gpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">Model</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Registers a model and returns a Model representing the registered Model resource.</span>

<span class="sd">    Args:</span>
<span class="sd">        model (Union[&quot;sklearn.base.BaseEstimator&quot;, &quot;tensorflow.Module&quot;, &quot;torch.nn.Module&quot;]):</span>
<span class="sd">            Required. An OSS model. Supported frameworks: sklearn, tensorflow, pytorch.</span>
<span class="sd">        use_gpu (bool):</span>
<span class="sd">            Optional. Whether to use GPU for model serving. Default to False.</span>

<span class="sd">    Returns:</span>
<span class="sd">        vertex_model (aiplatform.Model):</span>
<span class="sd">            Instantiated representation of the registered model resource.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError: if default staging bucket is not set</span>
<span class="sd">                    or if the framework is not supported.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">staging_bucket</span> <span class="o">=</span> <span class="n">vertexai</span><span class="o">.</span><span class="n">preview</span><span class="o">.</span><span class="n">global_config</span><span class="o">.</span><span class="n">staging_bucket</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">staging_bucket</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="s2">&quot;A default staging bucket is required to upload the model file. &quot;</span>
            <span class="s2">&quot;Please call `vertexai.init(staging_bucket=&#39;gs://my-bucket&#39;).&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Unwrap VertexRemoteFunctor before upload to Model Registry.</span>
    <span class="n">rewrapper</span> <span class="o">=</span> <span class="n">driver</span><span class="o">.</span><span class="n">_unwrapper</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

    <span class="n">serializer</span> <span class="o">=</span> <span class="n">any_serializer</span><span class="o">.</span><span class="n">AnySerializer</span><span class="p">()</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="vm">__module__</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;sklearn&quot;</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">_register_sklearn_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">serializer</span><span class="p">,</span> <span class="n">staging_bucket</span><span class="p">,</span> <span class="n">rewrapper</span><span class="p">)</span>

        <span class="k">elif</span> <span class="n">model</span><span class="o">.</span><span class="vm">__module__</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;keras&quot;</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;_tracking_metadata&quot;</span><span class="p">)</span>
        <span class="p">):</span>  <span class="c1"># pylint: disable=protected-access</span>
            <span class="k">return</span> <span class="n">_register_tf_model</span><span class="p">(</span>
                <span class="n">model</span><span class="p">,</span> <span class="n">serializer</span><span class="p">,</span> <span class="n">staging_bucket</span><span class="p">,</span> <span class="n">rewrapper</span><span class="p">,</span> <span class="n">use_gpu</span>
            <span class="p">)</span>

        <span class="k">elif</span> <span class="s2">&quot;torch&quot;</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="vm">__module__</span> <span class="ow">or</span> <span class="p">(</span><span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;state_dict&quot;</span><span class="p">)):</span>
            <span class="k">return</span> <span class="n">_register_pytorch_model</span><span class="p">(</span>
                <span class="n">model</span><span class="p">,</span> <span class="n">serializer</span><span class="p">,</span> <span class="n">staging_bucket</span><span class="p">,</span> <span class="n">rewrapper</span><span class="p">,</span> <span class="n">use_gpu</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Support uploading PyTorch, scikit-learn and TensorFlow only.&quot;</span>
            <span class="p">)</span>
    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">e</span>
    <span class="k">finally</span><span class="p">:</span>
        <span class="n">rewrapper</span><span class="p">(</span><span class="n">model</span><span class="p">)</span></div>


<div class="viewcode-block" id="from_pretrained"><a class="viewcode-back" href="../../../../../vertexai/services.html#vertexai.preview.from_pretrained">[docs]</a><span class="k">def</span> <span class="nf">from_pretrained</span><span class="p">(</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">model_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">custom_job_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">foundation_model_name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="s2">&quot;sklearn.base.BaseEstimator&quot;</span><span class="p">,</span> <span class="s2">&quot;tf.Module&quot;</span><span class="p">,</span> <span class="s2">&quot;torch.nn.Module&quot;</span><span class="p">]:</span>  <span class="c1"># noqa: F821</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Pulls a model from Model Registry or from a CustomJob ID for retraining.</span>

<span class="sd">    The returned model is wrapped with a Vertex wrapper for running remote jobs on Vertex,</span>
<span class="sd">    unless an unwrapped model was registered to Model Registry.</span>

<span class="sd">    Args:</span>
<span class="sd">        model_name (str):</span>
<span class="sd">            Optional. The resource ID or fully qualified resource name of a registered model.</span>
<span class="sd">            Format: &quot;12345678910&quot; or</span>
<span class="sd">            &quot;projects/123/locations/us-central1/models/12345678910@1&quot;. One of `model_name`,</span>
<span class="sd">            `custom_job_name`, or `foundation_model_name` is required.</span>
<span class="sd">        custom_job_name (str):</span>
<span class="sd">            Optional. The resource ID or fully qualified resource name of a CustomJob created</span>
<span class="sd">            with Vertex SDK remote training. If the job has completed successfully, this will load</span>
<span class="sd">            the trained model created in the CustomJob. One of `model_name`, `custom_job_name`, or</span>
<span class="sd">            `foundation_model_name` is required.</span>
<span class="sd">        foundation_model_name (str):</span>
<span class="sd">            Optional. The name of the foundation model to load. For example: &quot;text-bison@001&quot;. One of</span>
<span class="sd">            `model_name`,`custom_job_name`, or `foundation_model_name` is required.</span>

<span class="sd">    Returns:</span>
<span class="sd">        model: local model for uptraining.</span>

<span class="sd">    Raises:</span>
<span class="sd">        ValueError:</span>
<span class="sd">            If registered model is not registered through `vertexai.preview.register`</span>
<span class="sd">            If custom job was not created with Vertex SDK remote training</span>
<span class="sd">            If both or neither model_name or custom_job_name are provided</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_from_pretrained_passed_exactly_one_arg</span><span class="p">(</span><span class="nb">locals</span><span class="p">())</span>

    <span class="n">project</span> <span class="o">=</span> <span class="n">vertexai</span><span class="o">.</span><span class="n">preview</span><span class="o">.</span><span class="n">global_config</span><span class="o">.</span><span class="n">project</span>
    <span class="n">location</span> <span class="o">=</span> <span class="n">vertexai</span><span class="o">.</span><span class="n">preview</span><span class="o">.</span><span class="n">global_config</span><span class="o">.</span><span class="n">location</span>
    <span class="n">credentials</span> <span class="o">=</span> <span class="n">vertexai</span><span class="o">.</span><span class="n">preview</span><span class="o">.</span><span class="n">global_config</span><span class="o">.</span><span class="n">credentials</span>

    <span class="k">if</span> <span class="n">model_name</span><span class="p">:</span>

        <span class="n">vertex_model</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span>
            <span class="n">model_name</span><span class="p">,</span> <span class="n">project</span><span class="o">=</span><span class="n">project</span><span class="p">,</span> <span class="n">location</span><span class="o">=</span><span class="n">location</span><span class="p">,</span> <span class="n">credentials</span><span class="o">=</span><span class="n">credentials</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">vertex_model</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;registered_by_vertex_ai&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="s2">&quot;true&quot;</span><span class="p">:</span>

            <span class="n">artifact_uri</span> <span class="o">=</span> <span class="n">vertex_model</span><span class="o">.</span><span class="n">uri</span>
            <span class="n">model_file</span> <span class="o">=</span> <span class="n">_get_model_file_from_image_uri</span><span class="p">(</span>
                <span class="n">vertex_model</span><span class="o">.</span><span class="n">container_spec</span><span class="o">.</span><span class="n">image_uri</span>
            <span class="p">)</span>

            <span class="n">serializer</span> <span class="o">=</span> <span class="n">any_serializer</span><span class="o">.</span><span class="n">AnySerializer</span><span class="p">()</span>
            <span class="n">model</span> <span class="o">=</span> <span class="n">serializer</span><span class="o">.</span><span class="n">deserialize</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">artifact_uri</span><span class="p">,</span> <span class="n">model_file</span><span class="p">))</span>

            <span class="n">rewrapper</span> <span class="o">=</span> <span class="n">serializer</span><span class="o">.</span><span class="n">deserialize</span><span class="p">(</span>
                <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">artifact_uri</span><span class="p">,</span> <span class="n">_REWRAPPER_NAME</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="c1"># Rewrap model (in-place) for following remote training.</span>
            <span class="n">rewrapper</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">model</span>

        <span class="k">elif</span> <span class="ow">not</span> <span class="n">vertex_model</span><span class="o">.</span><span class="n">labels</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The model </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> was not registered through `vertexai.preview.register` or created from Model Garden.&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># Get the labels and check if it&#39;s a tuned model from a PublisherModel resource</span>
            <span class="k">for</span> <span class="n">label_key</span> <span class="ow">in</span> <span class="n">vertex_model</span><span class="o">.</span><span class="n">labels</span><span class="p">:</span>
                <span class="n">publisher_model_label</span> <span class="o">=</span> <span class="n">vertex_model</span><span class="o">.</span><span class="n">labels</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">label_key</span><span class="p">)</span>
                <span class="n">publisher_model_label_format_match</span> <span class="o">=</span> <span class="sa">r</span><span class="s2">&quot;(^[a-z]+-[a-z]+-[0-9]</span><span class="si">{3}</span><span class="s2">$)&quot;</span>

                <span class="k">if</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="n">publisher_model_label_format_match</span><span class="p">,</span> <span class="n">publisher_model_label</span><span class="p">):</span>
                    <span class="c1"># This try/except ensures this method will iterate over all models in a label even</span>
                    <span class="c1"># if one fails on PublisherModel resource creation</span>
                    <span class="n">short_model_id</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">_language_models</span><span class="o">.</span><span class="n">_get_model_id_from_tuning_model_id</span><span class="p">(</span>
                            <span class="n">publisher_model_label</span>
                        <span class="p">)</span>
                    <span class="p">)</span>

                    <span class="k">try</span><span class="p">:</span>
                        <span class="n">publisher_model</span> <span class="o">=</span> <span class="n">_get_publisher_model_resource</span><span class="p">(</span><span class="n">short_model_id</span><span class="p">)</span>
                        <span class="k">return</span> <span class="n">_model_garden_models</span><span class="o">.</span><span class="n">_from_pretrained</span><span class="p">(</span>
                            <span class="n">model_name</span><span class="o">=</span><span class="n">short_model_id</span><span class="p">,</span>
                            <span class="n">publisher_model</span><span class="o">=</span><span class="n">publisher_model</span><span class="p">,</span>
                            <span class="n">tuned_vertex_model</span><span class="o">=</span><span class="n">vertex_model</span><span class="p">,</span>
                        <span class="p">)</span>

                    <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
                        <span class="k">continue</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The model </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2"> was not created from a Model Garden model.&quot;</span>
            <span class="p">)</span>

    <span class="k">if</span> <span class="n">custom_job_name</span><span class="p">:</span>
        <span class="n">job</span> <span class="o">=</span> <span class="n">aiplatform</span><span class="o">.</span><span class="n">CustomJob</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="n">custom_job_name</span><span class="p">,</span> <span class="n">project</span><span class="o">=</span><span class="n">project</span><span class="p">,</span> <span class="n">location</span><span class="o">=</span><span class="n">location</span><span class="p">,</span> <span class="n">credentials</span><span class="o">=</span><span class="n">credentials</span>
        <span class="p">)</span>
        <span class="n">job_state</span> <span class="o">=</span> <span class="n">job</span><span class="o">.</span><span class="n">state</span>

        <span class="n">_verify_custom_job</span><span class="p">(</span><span class="n">job</span><span class="p">)</span>
        <span class="n">job_dir</span> <span class="o">=</span> <span class="n">job</span><span class="o">.</span><span class="n">job_spec</span><span class="o">.</span><span class="n">base_output_directory</span><span class="o">.</span><span class="n">output_uri_prefix</span>

        <span class="k">if</span> <span class="n">job_state</span> <span class="ow">in</span> <span class="n">aiplatform_jobs</span><span class="o">.</span><span class="n">_JOB_PENDING_STATES</span><span class="p">:</span>
            <span class="n">_LOGGER</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;The CustomJob </span><span class="si">{</span><span class="n">job</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2"> is still running. When the job has completed successfully, your model will be returned.&quot;</span>
            <span class="p">)</span>
            <span class="n">training</span><span class="o">.</span><span class="n">_get_remote_logs_until_complete</span><span class="p">(</span><span class="n">job</span><span class="p">)</span>
            <span class="c1"># Get the new job state after it has completed</span>
            <span class="n">job_state</span> <span class="o">=</span> <span class="n">job</span><span class="o">.</span><span class="n">state</span>

        <span class="k">if</span> <span class="n">job_state</span> <span class="o">==</span> <span class="n">gca_job_state</span><span class="o">.</span><span class="n">JobState</span><span class="o">.</span><span class="n">JOB_STATE_SUCCEEDED</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">_get_model_from_successful_custom_job</span><span class="p">(</span><span class="n">job_dir</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The provided job did not complete successfully. Please provide a pending or successful customJob ID.&quot;</span>
            <span class="p">)</span>

    <span class="k">if</span> <span class="n">foundation_model_name</span><span class="p">:</span>
        <span class="n">publisher_model</span> <span class="o">=</span> <span class="n">_get_publisher_model_resource</span><span class="p">(</span><span class="n">foundation_model_name</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">_model_garden_models</span><span class="o">.</span><span class="n">_from_pretrained</span><span class="p">(</span>
            <span class="n">model_name</span><span class="o">=</span><span class="n">foundation_model_name</span><span class="p">,</span> <span class="n">publisher_model</span><span class="o">=</span><span class="n">publisher_model</span>
        <span class="p">)</span></div>
</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../../index.html">google-cloud-aiplatform</a></h1>



<p class="blurb">Google Cloud Client Libraries for google-cloud-aiplatform</p>




<p>
<iframe src="https://ghbtns.com/github-btn.html?user=googleapis&repo=python-aiplatform&type=watch&count=true&size=large&v=2"
  allowtransparency="true" frameborder="0" scrolling="0" width="200px" height="35px"></iframe>
</p>





<h3>Navigation</h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../vertexai/services.html">Vertex AI SDK</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../../index.html">Documentation overview</a><ul>
  <li><a href="../../../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;2019, Google.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 5.0.2</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
    </div>

    
    <a href="https://github.com/googleapis/python-aiplatform" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://github.blog/wp-content/uploads/2008/12/forkme_right_darkblue_121621.png" alt="Fork me on GitHub"  class="github"/>
    </a>
    

    
  </body>
</html>